{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45ecc50-b0c2-4f8d-bcaa-b8aa665af015",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920565d-243e-41ca-87fe-6158590dcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.data import ITKReader\n",
    "from monai.data import DataLoader\n",
    "from monai.data import decollate_batch\n",
    "from monai.transforms import LoadImage, LoadImaged, Compose, RandFlipd, RandZoomd, ScaleIntensityd, Resized, EnsureType, EnsureTyped, Activations, AsDiscrete, Decollated, adaptor, RandRotated, ScaleIntensity, Resize, ConcatItemsd, ToTensord, SpatialCropd, CenterSpatialCropd, Rotated, EnsureChannelFirstd, MapTransform\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "from monai.handlers import from_engine, ValidationHandler, StatsHandler, TensorBoardStatsHandler, CheckpointSaver, TensorBoardImageHandler, ClassificationSaver, CheckpointLoader\n",
    "from monai.apps import get_logger\n",
    "from monai.utils import ImageMetaKey as Key\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import nibabel\n",
    "\n",
    "import ignite\n",
    "from ignite.metrics import Accuracy\n",
    "from ignite.engine import create_supervised_evaluator\n",
    "from ignite.engine import create_supervised_trainer\n",
    "from ignite.engine import Events\n",
    "\n",
    "import logging\n",
    "\n",
    "import sys\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import mlflow\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8ffa8-2a30-46a2-9d44-d035437f8050",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a3399-2a9f-4482-9261-742a0dc82a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = [1017,10251,13362,14642,15967,18516,24283,25964,29866,31592,32120,32248,43899,44323,46034,48151,50096,50156,54354,55034,56388,56890,57041,58325,59224,62591,65364,66028,67565,70158,70744,71067,75515,83014,83303,87267,90310,90614,95548] #39 StÃ¼ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db139c8-9f86-4e56-b291-ac961faf3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/f18-psma-pet-ct-ml/data/labels.tsv\", sep=\"\\t\")\n",
    "\n",
    "df = df.assign(pet=lambda df: df['pseudo_id'].map(lambda pseudo_id: \"/data/f18-psma-pet-ct-ml/cropped_nifti_urinary_bladder/\" + str(pseudo_id).zfill(5) + \"_pet.nii.gz\" if pseudo_id in empty else \"/data/f18-psma-pet-ct-ml/cropped_nifti_prostate/\" + str(pseudo_id).zfill(5) + \"_pet.nii.gz\"))\n",
    "df = df.assign(ct=lambda df: df['pseudo_id'].map(lambda pseudo_id: \"/data/f18-psma-pet-ct-ml/cropped_nifti_urinary_bladder/\" + str(pseudo_id).zfill(5) + \"_ct.nii.gz\" if pseudo_id in empty else \"/data/f18-psma-pet-ct-ml/cropped_nifti_prostate/\" + str(pseudo_id).zfill(5) + \"_ct.nii.gz\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262571ae-895e-4c0f-8f8c-f8c6a8eb81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "psa_normalized = scaler.fit_transform(df[[\"psa\"]])\n",
    "df[\"psa_norm\"] = psa_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e99671e-acfe-4f16-84f4-6f14e431390a",
   "metadata": {},
   "source": [
    "### Sort out some IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb1810-2950-4e7b-a718-6359bf75c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic = [13019, 53135, 94420, 32841, 80544, 84704, 26023, 80297, 85350, 80857, 55044, 18663, 20684, 87138, 97067, 76290, 96548, 40776, 21150, 37960, 54052, 30443, 64579, 93143, 27689, 73064, \n",
    "               9404, 31111, 4433, 21589, 42404, 29825, 52939, 45756, 8099, 93472,72491, 59397, 75553, 24480, 67496, 67384, 86676, 3543, 19369, 14932, 97053, 40931, 55904, 47830, 96595, 88341, 14382, \n",
    "               39, 14579, 20481, 58596, 90461, 90747]\n",
    "\n",
    "df = df[~df.pseudo_id.isin(problematic)]\n",
    "df = df[df.label != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827be27-d390-4d7c-b060-d9182f3c9a72",
   "metadata": {},
   "source": [
    "### Label correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f1ec8-93c6-4ac8-9e6b-64cb7f5b3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a416fd3-0603-4edb-a6e6-7f5b19db8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['label'] == 0) & (df['alt_label'] == 1), 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d64d6-f693-4a76-b6f4-05006b31cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7716f61-1ee5-4c21-858d-81ba2ce2e146",
   "metadata": {},
   "source": [
    "### Create sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b304c1-fa92-4edc-b355-71e1e7796dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = df.to_dict('records') \n",
    "train_data = df[df[\"set\"] == \"train\"].to_dict('records')\n",
    "val_data = df[df[\"set\"] == \"val\"].to_dict('records')\n",
    "#train_data = df[df[\"set\"] == \"train\"].iloc[0:1].to_dict('records')\n",
    "#val_data = df[df[\"set\"] == \"val\"].iloc[1:2].to_dict('records')\n",
    "print(f\"Complete: {len(complete_data)}\\nTraining: {len(train_data)}\\nValidation: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c902ccb1-4122-48ab-a9e5-3c4e55281e4e",
   "metadata": {},
   "source": [
    "### Defining the transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88352b-e4b4-42b5-bc5a-67183220d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Repeatd(MapTransform):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys,\n",
    "        target_size,\n",
    "    ) -> None:\n",
    "        MapTransform.__init__(self, keys, allow_missing_keys = True)\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "        d = dict(data)\n",
    "        for key in d:\n",
    "            if key in self.keys:\n",
    "                tensor = torch.Tensor([d[key]])\n",
    "                d[key] = tensor.repeat(*self.target_size)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8cdc8-f512-4f2c-88d8-37a79e1128cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"ct\",\"pet\"]),\n",
    "        EnsureChannelFirstd(keys=[\"ct\",\"pet\"]),\n",
    "        ScaleIntensityd(keys=[\"ct\",\"pet\"]),\n",
    "        Resized(keys=[\"ct\",\"pet\"], spatial_size=(70, 70, 70)),\n",
    "        #Repeatd(keys=[\"psa_norm\", \"px\"], target_size=(1, 70, 70, 70)),\n",
    "        EnsureTyped(keys=[\"ct\",\"pet\"]),  \n",
    "        ConcatItemsd(keys=[\"ct\", \"pet\"], name=\"petct\", dim=0),  \n",
    "                                              \n",
    "        ToTensord(keys=[\"petct\", \"ct\", \"pet\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfbb3e-76de-4c1e-8d09-aacb112ecf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pred = Compose([EnsureType(), Activations(softmax=True)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a1a40-abdf-4220-8b8e-f2ae5f756582",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61af7b-5a8c-404c-9a92-10ac518b3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_batch=lambda batch, device, non_blocking: (batch[\"petct\"].to(device), batch[\"label\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1f21e-c76f-429b-bd75-d4a89fd71bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the parameter \"block_inplanes\" in the ResNet networks\n",
    "def get_inplanes():\n",
    "    return [64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f89bbc-4c32-4c6e-97b7-9a4e095b60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the four different networks\n",
    "DenseNet121 = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=4, out_channels=2)\n",
    "DenseNet201 = monai.networks.nets.DenseNet201(spatial_dims=3, in_channels=4, out_channels=2)\n",
    "ResNet34 = monai.networks.nets.ResNet(block=\"basic\", layers=[3, 4, 6, 3], block_inplanes=get_inplanes(), spatial_dims=3, n_input_channels=4)\n",
    "ResNet50 = monai.networks.nets.ResNet(block=\"bottleneck\", layers=[3, 4, 6, 3], block_inplanes=get_inplanes(), spatial_dims=3, n_input_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a381e9-248d-42e7-ba7e-0448e7b0f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary \"models\"\n",
    "models = {\n",
    "    \"DenseNet121\": DenseNet121,\n",
    "    \"DenseNet201\": DenseNet201,\n",
    "    \"ResNet34\": ResNet34,\n",
    "    \"ResNet50\": ResNet50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2fd0f-8af5-44be-b5cc-431764c55f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optunas objective function to define the search space\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model - choice between four different models/networks\n",
    "    model_name = trial.suggest_categorical(\"model\", [\"DenseNet121\", \"DenseNet121\"])\n",
    "    model = models[model_name]\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        model.cuda(device)  \n",
    "    \n",
    "    # Define the search space for number of epochs and batch size\n",
    "    num_epochs = 15\n",
    "    #seed = trial.suggest_int(\"seed\", 1, 40)\n",
    "    batch_size = 16\n",
    "    batchsize = 16\n",
    "    \n",
    "    # Define the search space for the transforms - with minimum value, maximum value and step\n",
    "    prob_CSC = trial.suggest_float(\"prob_CSC\", 1, 1, step=1) # Probability for CenterSpatialCropd\n",
    "    prob_aug = trial.suggest_float(\"prob_aug\", 0, 1, step=0.1) # Probability for Augmentation(RandRotated, RandAxisFlipd, RandZoomd)\n",
    "    #prob_px = trial.suggest_float(\"prob_px\", 1, 1, step=1)\n",
    "    #csc_x = trial.suggest_int(\"csc_x\", 30, 70, step=1) # X value of CenterSpatialCropd roi_size\n",
    "    #csc_y = trial.suggest_int(\"csc_y\", 30, 70, step=1) # Y value of CenterSpatialCropd roi_size\n",
    "    #csc_z = trial.suggest_int(\"csc_z\", 30, 70, step=1) # Z value of CenterSpatialCropd roi_size\n",
    "    minzoom = trial.suggest_float(\"minzoom\", 0.5, 1.5, step=0.1)\n",
    "    maxzoom = trial.suggest_float(\"maxzoom\", 0.5, 1.5, step=0.1)\n",
    "\n",
    "    train_transforms = Compose([transforms,\n",
    "        #CenterSpatialCropd(keys=[\"ct\", \"pet\"], roi_size = (csc_x, csc_y, csc_z)),\n",
    "        Repeatd(keys=[\"psa_norm\", \"px\"], target_size=(1, 70, 70, 70)),\n",
    "        RandRotated(keys=[\"ct\",\"pet\"], prob=0.8, range_x=[-0.2,0.2], range_y=[-0.1,0.1], mode=['bilinear', 'nearest']),\n",
    "        #RandFlipd(keys=[\"ct\", \"pet\"], prob=prob_aug, spatial_axis=1), \n",
    "        RandZoomd(keys=[\"ct\", \"pet\"], prob=prob_aug, min_zoom=minzoom, max_zoom=maxzoom),\n",
    "        EnsureTyped(keys=[\"ct\",\"pet\", \"psa_norm\", \"px\"]),  \n",
    "        ConcatItemsd(keys=[\"ct\", \"pet\", \"psa_norm\", \"px\"], name=\"petct\", dim=0), \n",
    "    ])\n",
    "    \n",
    "    val_transforms = Compose([transforms, \n",
    "        #CenterSpatialCropd(keys=[\"ct\", \"pet\"], roi_size = (csc_x, csc_y, csc_z)),\n",
    "        Repeatd(keys=[\"psa_norm\", \"px\"], target_size=(1, 70, 70, 70)),\n",
    "        #RandRotated(keys=[\"ct\",\"pet\"], prob=0.8, range_x=[-0.2,0.2], range_y=[-0.1,0.1], mode=['bilinear', 'nearest']),\n",
    "        #RandFlipd(keys=[\"ct\", \"pet\"], prob=prob_aug, spatial_axis=1), \n",
    "        #RandZoomd(keys=[\"ct\", \"pet\"], prob=prob_aug, min_zoom=0.7, max_zoom=1.2),\n",
    "        EnsureTyped(keys=[\"ct\",\"pet\", \"psa_norm\", \"px\"]),  \n",
    "        ConcatItemsd(keys=[\"ct\", \"pet\", \"psa_norm\", \"px\"], name=\"petct\", dim=0),                      \n",
    "    ])\n",
    "\n",
    "    \n",
    "    # Generate the training and validation dataset and dataloader \n",
    "    train_ds = monai.data.Dataset(data=train_data, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batchsize, shuffle=True, num_workers=1, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "    val_ds = monai.data.Dataset(data=val_data, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batchsize, num_workers=1, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "\n",
    "    # Generate the optimizers and define the search space for the learning rate (Adam as optimizer seemed to perform better than SGD)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log = True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                \n",
    "    # Generate trainer and evaluator\n",
    "    trainer = create_supervised_trainer(model, optimizer, nn.CrossEntropyLoss(), device=device, prepare_batch=prepare_batch)\n",
    "    evaluator = create_supervised_evaluator(model, metrics={\"accuracy\": Accuracy()}, device=device, prepare_batch=prepare_batch)\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics={\"accuracy\": Accuracy()}, device=device, prepare_batch=prepare_batch)\n",
    "\n",
    "    # log the validation accuracy after every epoch and print its value\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_results(engine):\n",
    "        evaluator.run(val_loader)\n",
    "        validation_acc = evaluator.state.metrics[\"accuracy\"]\n",
    "        print(\"Epoch: {} Validation accuracy: {:.4f}\".format(engine.state.epoch, validation_acc))\n",
    "\n",
    "        train_evaluator.run(train_loader)\n",
    "        training_acc = train_evaluator.state.metrics[\"accuracy\"]\n",
    "        print(\"Epoch: {} Training accuracy: {:.4f}\".format(engine.state.epoch, training_acc))\n",
    "        \n",
    "        # attach the Pruner - Optuna should prune trials dependent on the validation accuracy\n",
    "        trial.report(validation_acc, engine.state.epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=num_epochs)\n",
    "\n",
    "    evaluator.run(val_loader)\n",
    "    return evaluator.state.metrics[\"accuracy\"]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8b639-8939-4900-a3da-7b2db84b08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration of MLflow - stores all experiment data in \"mlruns_trial_models\" folder\n",
    "mlflc = MLflowCallback(\n",
    "    tracking_uri=\"mlruns_trial_models\",\n",
    "    metric_name=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf687a-7344-48ac-8cee-1aaddce2b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage for the Optuna dashboard\n",
    "storage = \"sqlite:////data/f18-psma-pet-ct-ml/code/Code_Marko/Master/Code/Optuna/Optuna_SQLite1_7c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bceefc7-fd05-4a42-96a1-9ec382c7d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "    study = optuna.create_study(direction=\"maximize\", storage=storage, study_name=\"trial_models_marko\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=25, callbacks=[mlflc])\n",
    "    \n",
    "    study.set_user_attr(\"Loss_function\", \"CrossEntropyLoss\")\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "    print(f\"Sampler: {study.sampler.__class__.__name__}\")\n",
    "    print(f\"Pruner: {study.pruner.__class__.__name__}\")\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1781d717-61fe-48d6-8703-243b9507ef70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38f161-4122-406d-bd82-fa04566f54e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
