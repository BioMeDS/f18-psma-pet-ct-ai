{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.data import ITKReader\n",
    "from monai.data import DataLoader\n",
    "from monai.data import decollate_batch\n",
    "from monai.transforms import LoadImage, LoadImaged, Compose, ScaleIntensityd, RandFlipd, RandZoomd, Resized, EnsureType, EnsureTyped, Activations, AsDiscrete, Decollated, adaptor, RandRotated, ScaleIntensity, Resize, ConcatItemsd, ToTensord, SpatialCropd, CenterSpatialCropd, Rotated, EnsureChannelFirstd, MapTransform\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "from monai.handlers import from_engine, ValidationHandler, StatsHandler, TensorBoardStatsHandler, CheckpointSaver, TensorBoardImageHandler, ClassificationSaver, CheckpointLoader\n",
    "from monai.apps import get_logger\n",
    "from monai.utils import ImageMetaKey as Key\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import nibabel\n",
    "\n",
    "import ignite\n",
    "from ignite.metrics import Accuracy\n",
    "\n",
    "import logging\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = [1017,10251,13362,14642,15967,18516,24283,25964,29866,31592,32120,32248,43899,44323,46034,48151,50096,50156,54354,55034,56388,56890,57041,58325,59224,62591,65364,66028,67565,70158,70744,71067,75515,83014,83303,87267,90310,90614,95548] #39 StÃ¼ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/f18-psma-pet-ct-ml/data/labels.tsv\", sep=\"\\t\")\n",
    "\n",
    "df = df.assign(pet=lambda df: df['pseudo_id'].map(lambda pseudo_id: \"/data/f18-psma-pet-ct-ml/cropped_nifti_urinary_bladder/\" + str(pseudo_id).zfill(5) + \"_pet.nii.gz\" if pseudo_id in empty else \"/data/f18-psma-pet-ct-ml/cropped_nifti_prostate/\" + str(pseudo_id).zfill(5) + \"_pet.nii.gz\"))\n",
    "df = df.assign(ct=lambda df: df['pseudo_id'].map(lambda pseudo_id: \"/data/f18-psma-pet-ct-ml/cropped_nifti_urinary_bladder/\" + str(pseudo_id).zfill(5) + \"_ct.nii.gz\" if pseudo_id in empty else \"/data/f18-psma-pet-ct-ml/cropped_nifti_prostate/\" + str(pseudo_id).zfill(5) + \"_ct.nii.gz\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "psa_normalized = scaler.fit_transform(df[[\"psa\"]])\n",
    "df[\"psa_norm\"] = psa_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out some IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic = [13019, 53135, 94420, 32841, 80544, 84704, 26023, 80297, 85350, 80857, 55044, 18663, 20684, 87138, 97067, 76290, 96548, 40776, 21150, 37960, 54052, 30443, 64579, 93143, 27689, 73064, \n",
    "               9404, 31111, 4433, 21589, 42404, 29825, 52939, 45756, 8099, 93472,72491, 59397, 75553, 24480, 67496, 67384, 86676, 3543, 19369, 14932, 97053, 40931, 55904, 47830, 96595, 88341, 14382, \n",
    "               39, 14579, 20481, 58596, 90461, 90747]\n",
    "\n",
    "df = df[~df.pseudo_id.isin(problematic)]\n",
    "df = df[df.label != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['label'] == 0) & (df['alt_label'] == 1), 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = df.to_dict('records') \n",
    "train_data = df[df[\"set\"] == \"train\"].to_dict('records')\n",
    "val_data = df[df[\"set\"] == \"val\"].to_dict('records')\n",
    "#train_data = df[df[\"set\"] == \"train\"].iloc[0:1].to_dict('records')\n",
    "#val_data = df[df[\"set\"] == \"val\"].iloc[1:2].to_dict('records')\n",
    "print(f\"Complete: {len(complete_data)}\\nTraining: {len(train_data)}\\nValidation: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Repeatd(MapTransform):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys,\n",
    "        target_size,\n",
    "    ) -> None:\n",
    "        MapTransform.__init__(self, keys, allow_missing_keys = True)\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "        d = dict(data)\n",
    "        for key in d:\n",
    "            if key in self.keys:\n",
    "                d[key] = torch.Tensor([d[key]]).repeat(*self.target_size)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"ct\",\"pet\"]),  \n",
    "        EnsureChannelFirstd(keys=[\"ct\",\"pet\"]), \n",
    "        ScaleIntensityd(keys=[\"ct\",\"pet\"]), \n",
    "        Resized(keys=[\"ct\",\"pet\"], spatial_size=(70, 70, 70)), \n",
    "        Repeatd(keys=[\"psa_norm\", \"px\"], target_size=(1, 70, 70, 70)),\n",
    "        #CenterSpatialCropd(keys=[\"ct\", \"pet\"], roi_size = (30, 40, 30)),\n",
    "        RandZoomd(keys=[\"ct\", \"pet\"], prob=0.7, min_zoom=0.5, max_zoom=1.5),\n",
    "        RandRotated(keys=[\"ct\",\"pet\"], prob=0.8, range_x=[-0.2,0.2], range_y=[-0.1,0.1], mode=['bilinear', 'nearest']),                                                                                                              \n",
    "        EnsureTyped(keys=[\"ct\",\"pet\", \"psa_norm\", \"px\"]),  \n",
    "        ConcatItemsd(keys=[\"ct\", \"pet\", \"psa_norm\", \"px\"], name=\"petct\", dim=0),  \n",
    "                                              \n",
    "        ToTensord(keys=[\"petct\", \"ct\", \"pet\"]),  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"ct\",\"pet\"]),\n",
    "        EnsureChannelFirstd(keys=[\"ct\",\"pet\"]),\n",
    "        ScaleIntensityd(keys=[\"ct\",\"pet\"]),\n",
    "        Resized(keys=[\"ct\",\"pet\"], spatial_size=(70, 70, 70)),\n",
    "        Repeatd(keys=[\"psa_norm\", \"px\"], target_size=(1, 70, 70, 70)),\n",
    "        #CenterSpatialCropd(keys=[\"ct\", \"pet\"], roi_size = (30, 40, 30)),\n",
    "        EnsureTyped(keys=[\"ct\",\"pet\", \"psa_norm\", \"px\"]),  \n",
    "        ConcatItemsd(keys=[\"ct\", \"pet\", \"psa_norm\", \"px\"], name=\"petct\", dim=0),  \n",
    "                                              \n",
    "        ToTensord(keys=[\"petct\", \"ct\", \"pet\"]),\n",
    "    ]\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_ds = monai.data.Dataset(data=complete_data, transform=val_transforms)\n",
    "complete_loader = DataLoader(complete_ds, batch_size=batchsize, num_workers=1, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "train_ds = monai.data.Dataset(data=train_data, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batchsize, shuffle=True, num_workers=1, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "val_ds = monai.data.Dataset(data=val_data, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batchsize, num_workers=1, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=4, out_channels=2).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SupervisedTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "get_logger(\"train_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_batch = lambda batch, device, non_blocking: (batch[\"petct\"].to(device), batch[\"label\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pids(batch):\n",
    "  return {Key.FILENAME_OR_OBJ: from_engine([\"pseudo_id\"])(batch)}\n",
    "\n",
    "\n",
    "def output_for_csv(output):\n",
    "\tres = from_engine([\"pred\", \"label\"])(output)\n",
    "\treturn [torch.concat([res[0][i], res[0][i].argmax().unsqueeze(0), torch.Tensor([res[1][i]]).to(device)]) for i in range(len(res[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create handlers + Trainer and Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_handlers = [\n",
    "    StatsHandler(name=\"train_log\", output_transform=lambda x: None),\n",
    "    TensorBoardStatsHandler(log_dir=\"/data/f18-psma-pet-ct-ml/runs_prostate_marko_model7c\", output_transform=lambda x: None),\n",
    "    CheckpointSaver(save_dir=\"/data/f18-psma-pet-ct-ml/runs_prostate_marko_model7c\", save_dict={\"net\": model}, save_key_metric=True),\n",
    "    ClassificationSaver(output_dir=\"/data/f18-psma-pet-ct-ml/code/Code_Marko/Master/Files\", filename=\"predictions_model7c.csv\", delimiter=\"\\t\", overwrite=True, output_transform=output_for_csv, batch_transform=get_pids)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = SupervisedEvaluator(\n",
    "    device = device,\n",
    "    val_data_loader = val_loader,\n",
    "    network = model,\n",
    "    prepare_batch = prepare_batch,\n",
    "    key_val_metric = {\"val_acc\": Accuracy(output_transform = from_engine([\"pred\", \"label\"]))},\n",
    "    val_handlers = val_handlers,\n",
    "    amp = True if monai.utils.get_torch_version_tuple() >= (1, 6) else False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_handlers = [\n",
    "    ValidationHandler(validator=evaluator, interval=1, epoch_level=True),\n",
    "    StatsHandler(name=\"train_log\", tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)),\n",
    "    TensorBoardStatsHandler(log_dir=\"/data/f18-psma-pet-ct-ml/runs_prostate_marko_model7c\", tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)),\n",
    "    CheckpointSaver(save_dir=\"/data/f18-psma-pet-ct-ml/runs_prostate_marko_model7c\", save_dict={\"net\": model, \"opt\": optimizer}, save_interval=1, epoch_level=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SupervisedTrainer(\n",
    "    device = device,\n",
    "    max_epochs = 15,\n",
    "    train_data_loader = train_loader,\n",
    "    network = model,\n",
    "    optimizer = optimizer,\n",
    "    loss_function = loss_function,\n",
    "    prepare_batch = prepare_batch,\n",
    "    key_train_metric = {\"train_acc\": Accuracy(output_transform=from_engine([\"pred\", \"label\"]))},\n",
    "    train_handlers = train_handlers,\n",
    "    amp = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluator.get_validation_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_epoch = evaluator.state.best_metric_epoch\n",
    "#print(best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handler = CheckpointLoader(f\"/data/runs_prostate_marko_model2/checkpoint_epoch={best_epoch}.pt\", load_dict={\"net\": model, \"opt\": optimizer})\n",
    "#handler(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/data/f18-psma-pet-ct-ml/code/Code_Marko/...\",sep=\"\\t\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#for batch in iter(complete_loader):\n",
    "#    IDs = batch[\"pseudo_id\"]\n",
    "#    Preds = model(batch[\"petct\"].to(device)).argmax(dim=1)\n",
    "#    for ID, Pred in zip(IDs, Preds):\n",
    "#        df.loc[df.pseudo_id == ID.item(), 'model 2'] = Pred.item()\n",
    "#        print(ID, Pred)\n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(path_or_buf=\"/data/f18-psma-pet-ct-ml/code/Code_Marko/...\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir=/data/runs_prostate_marko_model1 --port=12345"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
